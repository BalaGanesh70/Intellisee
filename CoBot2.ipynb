{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a0e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbd2dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load Hugging Face object detection pipeline\n",
    "object_detector = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669af651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert OpenCV frame to PIL and run detection\n",
    "def detect_objects(frame):\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(rgb)\n",
    "    results = object_detector(pil_img)\n",
    "    detected_labels = [res['label'].lower() for res in results if res['score'] > 0.7]\n",
    "    print(\" Detected objects:\", detected_labels)\n",
    "    return detected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92381f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple speech-to-text and token splitting\n",
    "def listen_and_understand():\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "\n",
    "    with mic as source:\n",
    "        print(\" Listening for command...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        command = recognizer.recognize_google(audio)\n",
    "        print(f\" You said: {command}\")\n",
    "        tokens = command.lower().split()  # Avoid using nltk.word_tokenize\n",
    "        return command, tokens\n",
    "    except sr.UnknownValueError:\n",
    "        print(\" Could not understand audio\")\n",
    "        return \"\", []\n",
    "    except sr.RequestError as e:\n",
    "        print(f\" Speech error: {e}\")\n",
    "        return \"\", []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b69be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_task(detected, tokens):\n",
    "    for obj in detected:\n",
    "        if obj in tokens:\n",
    "            print(f\"n = {obj} recognized and matched with the command\")\n",
    "            print(\"Action:\")\n",
    "            \n",
    "            if obj == \"bottle\":\n",
    "                print(\"- Take the bottle that is far away.\")\n",
    "                print(\"- Use your hand to lift the bottle.\")\n",
    "                print(\"- Pick it up and show it in the camera.\")\n",
    "\n",
    "            elif obj == \"plate\":\n",
    "                print(\"- Move toward the plate on the table.\")\n",
    "                print(\"- Slide the plate gently to the right.\")\n",
    "                print(\"- Lift the plate and place it at the desired location.\")\n",
    "\n",
    "            elif obj == \"cup\":\n",
    "                print(\"- Reach for the cup carefully.\")\n",
    "                print(\"- Grip the cup handle with your fingers.\")\n",
    "                print(\"- Lift the cup and place it near the bottle.\")\n",
    "\n",
    "            elif obj == \"book\":\n",
    "                print(\"- Identify the book on the surface.\")\n",
    "                print(\"- Pick up the book from the top.\")\n",
    "                print(\"- Hold the book up to show the cover to the camera.\")\n",
    "\n",
    "            elif obj == \"remote\":\n",
    "                print(\"- Locate the remote beside the book.\")\n",
    "                print(\"- Grab the remote using your fingers.\")\n",
    "                print(\"- Point it towards the screen and press the power button.\")\n",
    "\n",
    "            elif obj == \"person\":\n",
    "                print(\"- Approach the person carefully.\")\n",
    "                print(\"- Wave your hand to get their attention.\")\n",
    "                print(\"- Communicate the necessary instructions.\")\n",
    "\n",
    "            elif obj == \"tie\":\n",
    "                print(\"- Identify the tie on the person.\")\n",
    "                print(\"- Adjust it gently if needed.\")\n",
    "                print(\"- Ensure it is visible to the camera.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"- Perform an action related to the {obj}.\")\n",
    "            return f\"{obj} matched\"\n",
    "\n",
    "    print(\" No relevant object found in the command.\")\n",
    "    return \"No action taken.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f99c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Press 'c' to capture and speak a command, 'q' to quit.\n",
      "ü§ñ Detected objects: ['person', 'tie', 'person', 'cell phone', 'person', 'person']\n",
      "üéôÔ∏è Listening for command...\n",
      "üó£Ô∏è You said: take the notebook\n",
      "ü§ñ No relevant object found in the command.\n",
      "ü§ñ Decision: No action taken.\n"
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\" Press 'c' to capture and speak a command, 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\" Failed to read from webcam.\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Live Feed - Press 'c' to capture\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            # Step 1: Object Detection\n",
    "            detected = detect_objects(frame)\n",
    "\n",
    "            # Step 2: Voice Command Recognition\n",
    "            command_text, tokens = listen_and_understand()\n",
    "\n",
    "            # Step 3: Match & Respond\n",
    "            decision = decide_task(detected, tokens)\n",
    "            print(\" Decision:\", decision)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
